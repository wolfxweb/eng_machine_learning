{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " mlflow ui --backend-store-uri sqlite:///mlruns.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importações\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import *\n",
    "import os\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação data set  https://www.kaggle.com/c/kobe-bryant-shot-selection/data\n",
    "df = pd.read_parquet(\"../data/raw/dataset_kobe_dev.parquet\")\n",
    "df.shape\n",
    "# df_origianal.columns\n",
    "\n",
    "df_prod = pd.read_parquet(\"../data/raw/dataset_kobe_prod.parquet\")\n",
    "\n",
    "url_docs_artefatos = \"../docs/artefatos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para usar o sqlite como repositorio\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "experiment_name = 'PreparacaoDados'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para adicionar data frame como artefato \n",
    "def adicionaDataFrameArtefato(df, titulo,pasta):\n",
    "    #Salvar o DataFrame como arquivo parquet\n",
    "    arquivo_path = f\"../data/{pasta}/{titulo}.parquet\"\n",
    "    df.to_parquet(arquivo_path, index=False)\n",
    "    # Registrando o DataFrame resultante como um artefato no MLflow\n",
    "    mlflow.log_artifact(arquivo_path, f\"{titulo}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variavel com caminho do csv temporario, este foi criado para ser salvo como um aterfato no mlflow\n",
    "csv_path = ''\n",
    "\n",
    "def dadosNulosArtefato(df,titulo):\n",
    "    # Contagem de valores nulos por coluna\n",
    "    valores_nulos_por_coluna = df.isnull().sum()\n",
    "\n",
    "    # Criando um DataFrame para exibir os resultados\n",
    "    tabela_valores_nulos = pd.DataFrame(valores_nulos_por_coluna, columns=['Valores Nulos'])\n",
    "\n",
    "    # Resetando o índice para manter os nomes das colunas\n",
    "    tabela_valores_nulos.reset_index(inplace=True)\n",
    "\n",
    "    # Salvando o DataFrame como um arquivo CSV \n",
    "    csv_path = f\"{url_docs_artefatos}/texto/{titulo}.csv\"\n",
    "    tabela_valores_nulos.to_csv(csv_path, index=False)\n",
    "    \n",
    "    #Adicionado um atefato em formato csv com para listar os campos nullos\n",
    "    mlflow.log_artifact(csv_path, artifact_path= f\"{titulo}.csv\")\n",
    "    \n",
    "   # os.remove(csv_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_shape = \"\"\n",
    "\n",
    "def shapeArtefato(df, titulo):\n",
    "    # Obtendo o número de linhas e colunas do DataFrame\n",
    "    num_linhas = df.shape[0]\n",
    "    num_colunas = df.shape[1]\n",
    "    # Criando um DataFrame com as informações\n",
    "    info_shape = pd.DataFrame({'Número de Linhas': [num_linhas], 'Número de Colunas': [num_colunas]})\n",
    "\n",
    "    # Salvando o DataFrame como um arquivo CSV \n",
    "    csv_shape = f\"{url_docs_artefatos}/texto/{titulo}.csv\"\n",
    "    info_shape.to_csv(csv_shape, index=False)\n",
    "    #Adicionado artefato com a quantidade inicial de linha e colunas \n",
    "    mlflow.log_artifact(csv_shape, artifact_path=f\"{titulo}.csv\")\n",
    "    #os.remove(csv_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando artefato com os nomes da colunas originais e sua tipagem\n",
    "def colunasArtefato(df, titulo):\n",
    "    # Capturando as informações de df.info() em uma string\n",
    "    info_buffer = StringIO()\n",
    "    df.info(buf=info_buffer)\n",
    "    info_text = info_buffer.getvalue()\n",
    "      # Criando o caminho para a pasta\n",
    "    \n",
    "    pasta_path = os.path.join(url_docs_artefatos,'texto')\n",
    "    os.makedirs(pasta_path, exist_ok=True)\n",
    "    \n",
    "    # Salvando o arquivo de texto na pasta\n",
    "    file_path = os.path.join(pasta_path, f\"{titulo}.txt\")\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(info_text)\n",
    "    mlflow.log_text(info_text, artifact_file=f\"{titulo}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFrameArtefato(df, titulo,pasta):\n",
    "    #Colunas que irão permanecer na base de dados\n",
    "    colunas_selecionadas = ['lat','lon','minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']\n",
    "    #excutando a remoção de colunas e linha que tenha valores nuloes    \n",
    "    df_processado = df[colunas_selecionadas].dropna()\n",
    "    colunasArtefato(df_processado, f\"colunas_{titulo}\")\n",
    "    shapeArtefato(df_processado, f\"shape_{titulo}\")\n",
    "    dadosNulosArtefato(df_processado,f\"valores_nulos_{titulo}\") \n",
    "    \n",
    "    # Registrando o DataFrame resultante como um artefato no MLflow\n",
    "    adicionaDataFrameArtefato(df_processado,titulo,pasta)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_faixa_dinamica(df,pasta):\n",
    "   # dfp =  pd.read_parquet(\"../data/processed/data_filtered.parquet\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, palette=\"Set3\", linewidth=2.5)\n",
    "    plt.title(\"Gráfico de Box Plot - Faixa Dinâmica das Variáveis\")\n",
    "    plt.xlabel(\"Variáveis\")\n",
    "    plt.ylabel(\"Valores\")\n",
    "    plt.xticks(rotation=45)\n",
    "  #  plt.tight_layout()\n",
    "    \n",
    "    # Salvar o gráfico como uma imagem temporária\n",
    "    temp_file =  f\"{url_docs_artefatos}/graficos/{pasta}/boxplot_faixa_dinamica.png\"\n",
    "    plt.savefig(temp_file)\n",
    "    mlflow.log_artifact(temp_file, artifact_path=\"boxplot_faixa_dinamica.png\")\n",
    "    \n",
    "  #  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramaVariaveis(df,pasta):\n",
    "    #dfp =  pd.read_parquet(\"../data/processed/data_filtered.parquet\") \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    df.hist(figsize=(12, 8))\n",
    "    plt.suptitle(\"Histograma das Variáveis\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    histogram_path =  f\"{url_docs_artefatos}/graficos/{pasta}/histograma.png\"\n",
    "    plt.savefig(histogram_path)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(histogram_path, artifact_path=\"histograma.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrixCorrelacao(df,pasta):\n",
    "   # dfp =  pd.read_parquet(\"../data/processed/data_filtered.parquet\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "    plt.title(\"Matriz de Correlação\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salvar o gráfico como um arquivo temporário\n",
    "    temp_file =  f\"{url_docs_artefatos}/graficos/{pasta}/matriz_correlacao.png\"\n",
    "    plt.savefig(temp_file)\n",
    "    plt.close()\n",
    "    \n",
    "    mlflow.log_artifact(temp_file, artifact_path=\"matriz_correlacao.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScatterMatrix(df,pasta):\n",
    "    scatter_matrix(df, diagonal='hist', figsize=(15, 15))\n",
    "    plt.suptitle(\"Matriz de Gráficos de Dispersão\", y=0.90, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salvar o gráfico como um arquivo temporário\n",
    "    temp_file = f\"{url_docs_artefatos}/graficos/{pasta}/scatter_matrix.png\"\n",
    "    plt.savefig(temp_file)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(temp_file, artifact_path=\"scatter_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvDescribe(df, pasta):\n",
    "      # Obter estatísticas resumidas usando o método describe()\n",
    "    describe_stats = df.describe()\n",
    "    \n",
    "    # Converter as estatísticas resumidas para uma string\n",
    "    describe_string = describe_stats.to_string()\n",
    "\n",
    "    # Caminho do arquivo temporário para salvar as estatísticas resumidas\n",
    "    temp_path = f\"{url_docs_artefatos}/{pasta}/describe_statistics.txt\"\n",
    "    \n",
    "    # Salvar as estatísticas resumidas em um arquivo de texto\n",
    "    with open(temp_path, \"w\") as file:\n",
    "        file.write(describe_string)\n",
    "    \n",
    "    # Registrar o arquivo de texto como um artefato no MLflow\n",
    "    mlflow.log_artifact(temp_path, artifact_path=\"describe_statistics.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faixaDinamica(df):\n",
    "    # Calcular a faixa dinâmica de cada variável\n",
    "    range = df.max() - df.min()\n",
    "    \n",
    "    # Exportar os dados para um arquivo de texto\n",
    "    range.to_csv(f'{url_docs_artefatos}/texto/faixa_dinamica.txt', header=False, index=True)\n",
    "\n",
    "    # Registrar a faixa dinâmica de cada variável\n",
    "    for column, value in range.items():\n",
    "        mlflow.log_metric(f\"range_{column}\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividirBaseTreinoTeste(df, train_ratio= 0.8, test_ratio = 0.2):\n",
    "    # Dividir os dados em conjuntos de treino e teste com estratificação\n",
    "    # train_data, test_data = train_test_split(df, test_size=0.2, stratify=df['shot_made_flag'])\n",
    "   # train_ratio=0.8\n",
    "   # test_ratio = 0.2\n",
    "    # Dividir os dados em conjuntos de treino e teste com estratificação\n",
    "    train_data, test_data = train_test_split(df, test_size=1 - train_ratio, stratify=df['shot_made_flag'])\n",
    "\n",
    "    # Registrar os parâmetros no MLflow\n",
    "    mlflow.log_param(\"train_ratio\", train_ratio)\n",
    "    mlflow.log_param(\"test_ratio\", test_ratio)\n",
    "\n",
    "    # Salvar os conjuntos de treino e teste em arquivos Parquet\n",
    "    train_data.to_parquet(\"../data/processed/base_train.parquet\", index=False)\n",
    "    test_data.to_parquet(\"../data/processed/base_test.parquet\", index=False)\n",
    "\n",
    "    # Registrar as métricas no MLflow\n",
    "    mlflow.log_metric(\"base_train_size\", len(train_data))\n",
    "    mlflow.log_metric(\"base_test_size\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLflow\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name='PreparaçãoDados'):\n",
    "   \n",
    "   colunasArtefato(df,\"colunas_iniciais\")#Adicionado artefato com os nomes das colunas e sua respecitva tipagem \n",
    "   dadosNulosArtefato(df, \"valores_nulos\") #Adicionado um atefato em formato csv com para listar os campos nullos\n",
    "   \n",
    "   shapeArtefato(df,\"shape_inicial\")#Adicionado artefato com a quatidade de linhas e colunas iniciais\n",
    "   adicionaDataFrameArtefato(df,\"dataset_kobe_dev\",\"raw\") #Adiciondo o data frame de desenvolvimento com atefato no mlflow\n",
    "   adicionaDataFrameArtefato(df_prod,\"dataset_kobe_prod\",\"raw\") #Adiciondo o data frame de  produção com atefato no mlflow\n",
    "   dataFrameArtefato(df,\"data_filtered\",\"processed\") #Processando o data frame removendo algumas colunas e salvando o mesmo no mlflow\n",
    "   \n",
    "  \n",
    "   \"\"\"\n",
    "    Os artefatos abaixo são criados após o processamento dos dados. \n",
    "    Como esse processo pode levar algum tempo, uma validação foi adicionada para verificar se o arquivo já foi criado.\n",
    "    Se o arquivo já existe, os artefatos são criados a partir dele. Caso contrário, o processo de criação dos artefatos é iniciado.\n",
    "   \"\"\" \n",
    "   file_path = \"../data/processed/data_filtered.parquet\"\n",
    "   attempts = 0\n",
    "   max_attempts=100\n",
    "   while attempts < max_attempts:\n",
    "        if os.path.exists(file_path):  # Verifica se o arquivo existe\n",
    "            data_filtered =  pd.read_parquet(\"../data/processed/data_filtered.parquet\")\n",
    "            boxplot_faixa_dinamica(data_filtered,\"pre_processamento\")#adicioando grafico faixa dinamica como artefato\n",
    "            histogramaVariaveis(data_filtered,\"pre_processamento\")#adicionado o histograma como artefato\n",
    "            matrixCorrelacao(data_filtered,\"pre_processamento\")#adicionando matriz de correlação como artefato\n",
    "            plotScatterMatrix(data_filtered,\"pre_processamento\")#adicinando plot scatter marix como artefato \n",
    "            csvDescribe(data_filtered, \"texto\")# # Adiciona o gráfico da faixa dinâmica como artefato\n",
    "            dividirBaseTreinoTeste(data_filtered)\n",
    "            faixaDinamica(data_filtered)\n",
    "            \n",
    "            \n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            print(f\"O arquivo {file_path} não foi encontrado. Tentando novamente em 5 segundos...\")\n",
    "            time.sleep(5)  # Espera 5 segundos antes de tentar novamente\n",
    "            attempts += 1\n",
    "   else:\n",
    "        print(f\"Não foi possível encontrar o arquivo após {max_attempts} tentativas.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
